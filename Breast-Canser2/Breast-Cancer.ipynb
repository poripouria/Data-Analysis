{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libreries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "    Analyzing and predicting Breast Cancer by NN and MLP\n",
    "    \"Adult_TesrDataset.csv\" is the datasets\n",
    "    Project for Amirkabir University of Technilogy (Tehran Polytechnic)\n",
    "    Computer Scince department\n",
    "    Data Mining Course\n",
    "\n",
    "Student Name & ID: Pouria Alimoradpor 9912035\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Activation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/breast cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1        17.99         10.38          122.80   \n",
       "1      842517          1        20.57         17.77          132.90   \n",
       "2    84300903          1        19.69         21.25          130.00   \n",
       "3    84348301          1        11.42         20.38           77.58   \n",
       "4    84358402          1        20.29         14.34          135.10   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1        21.56         22.39          142.00   \n",
       "565    926682          1        20.13         28.25          131.20   \n",
       "566    926954          1        16.60         28.08          108.30   \n",
       "567    927241          1        20.60         29.33          140.10   \n",
       "568     92751          0         7.76         24.54           47.92   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                0.14710  ...        25.380          17.33           184.60   \n",
       "1                0.07017  ...        24.990          23.41           158.80   \n",
       "2                0.12790  ...        23.570          25.53           152.50   \n",
       "3                0.10520  ...        14.910          26.50            98.87   \n",
       "4                0.10430  ...        22.540          16.67           152.20   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564              0.13890  ...        25.450          26.40           166.10   \n",
       "565              0.09791  ...        23.690          38.25           155.00   \n",
       "566              0.05302  ...        18.980          34.12           126.70   \n",
       "567              0.15200  ...        25.740          39.42           184.60   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 32', axis=1)\n",
    "df[\"diagnosis\"] = df[\"diagnosis\"].map({'M':1,'B':0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236405</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.236403</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431741</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.432121</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.432201</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0 -0.236405   1.097064    -2.073335      1.269934        0.984375   1.568466   \n",
       "1 -0.236403   1.829821    -0.353632      1.685955        1.908708  -0.826962   \n",
       "2  0.431741   1.579888     0.456187      1.566503        1.558884   0.942210   \n",
       "3  0.432121  -0.768909     0.253732     -0.592687       -0.764464   3.283553   \n",
       "4  0.432201   1.750297    -1.151816      1.776573        1.826229   0.280372   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         3.283515          2.652874        2.532475             2.217515   \n",
       "1        -0.487072         -0.023846        0.548144             0.001392   \n",
       "2         1.052926          1.363478        2.037231             0.939685   \n",
       "3         3.402909          1.915897        1.451707             2.867383   \n",
       "4         0.539340          1.371011        1.428493            -0.009560   \n",
       "\n",
       "   ...  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0  ...              1.886690     -1.359293       2.303601         2.001237   \n",
       "1  ...              1.805927     -0.369203       1.535126         1.890489   \n",
       "2  ...              1.511870     -0.023974       1.347475         1.456285   \n",
       "3  ...             -0.281464      0.133984      -0.249939        -0.550021   \n",
       "4  ...              1.298575     -1.466770       1.338539         1.220724   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0    1.307686          2.616665           2.109526         2.296076   \n",
       "1   -0.375612         -0.430444          -0.146749         1.087084   \n",
       "2    0.527407          1.082932           0.854974         1.955000   \n",
       "3    3.394275          3.893397           1.989588         2.175786   \n",
       "4    0.220556         -0.313395           0.613179         0.729259   \n",
       "\n",
       "   concave points_worst  symmetry_worst  \n",
       "0              2.750622        1.937015  \n",
       "1             -0.243890        0.281190  \n",
       "2              1.152255        0.201391  \n",
       "3              6.046041        4.935010  \n",
       "4             -0.868353       -0.397100  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop('diagnosis', axis=1))\n",
    "scaled_features = scaler.transform(df.drop('diagnosis', axis=1))\n",
    "df_feat = pd.DataFrame(scaled_features, columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df_feat\n",
    "y = df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 30s 121ms/step - loss: 0.5677 - accuracy: 0.7563 - val_loss: 0.5022 - val_accuracy: 0.8012\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8945 - val_loss: 0.3756 - val_accuracy: 0.8947\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2873 - accuracy: 0.9497 - val_loss: 0.3028 - val_accuracy: 0.9298\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2262 - accuracy: 0.9598 - val_loss: 0.2534 - val_accuracy: 0.9298\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9648 - val_loss: 0.2191 - val_accuracy: 0.9415\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.9724 - val_loss: 0.1946 - val_accuracy: 0.9415\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1290 - accuracy: 0.9774 - val_loss: 0.1771 - val_accuracy: 0.9474\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9749 - val_loss: 0.1647 - val_accuracy: 0.9415\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9774 - val_loss: 0.1552 - val_accuracy: 0.9415\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9774 - val_loss: 0.1483 - val_accuracy: 0.9415\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9774 - val_loss: 0.1427 - val_accuracy: 0.9298\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9824 - val_loss: 0.1393 - val_accuracy: 0.9357\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9849 - val_loss: 0.1364 - val_accuracy: 0.9415\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 0.1343 - val_accuracy: 0.9415\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9874 - val_loss: 0.1321 - val_accuracy: 0.9415\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9874 - val_loss: 0.1314 - val_accuracy: 0.9474\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9899 - val_loss: 0.1297 - val_accuracy: 0.9474\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9899 - val_loss: 0.1296 - val_accuracy: 0.9415\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9925 - val_loss: 0.1293 - val_accuracy: 0.9474\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9925 - val_loss: 0.1299 - val_accuracy: 0.9474\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9925 - val_loss: 0.1293 - val_accuracy: 0.9474\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9925 - val_loss: 0.1291 - val_accuracy: 0.9474\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9950 - val_loss: 0.1290 - val_accuracy: 0.9474\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9950 - val_loss: 0.1298 - val_accuracy: 0.9474\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9950 - val_loss: 0.1303 - val_accuracy: 0.9474\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.1304 - val_accuracy: 0.9532\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.1312 - val_accuracy: 0.9532\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 0.1323 - val_accuracy: 0.9532\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.1347 - val_accuracy: 0.9532\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.1354 - val_accuracy: 0.9532\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.1363 - val_accuracy: 0.9474\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 0.1378 - val_accuracy: 0.9474\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9975 - val_loss: 0.1383 - val_accuracy: 0.9474\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.1393 - val_accuracy: 0.9474\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.1406 - val_accuracy: 0.9474\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.1409 - val_accuracy: 0.9474\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.1420 - val_accuracy: 0.9474\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.1435 - val_accuracy: 0.9474\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.1439 - val_accuracy: 0.9474\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.1461 - val_accuracy: 0.9474\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.1480 - val_accuracy: 0.9474\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.1489 - val_accuracy: 0.9474\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.1509 - val_accuracy: 0.9474\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.1529 - val_accuracy: 0.9474\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1546 - val_accuracy: 0.9474\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.1548 - val_accuracy: 0.9474\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.1554 - val_accuracy: 0.9474\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1575 - val_accuracy: 0.9474\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9474\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9474\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9474\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9474\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9474\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9474\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9474\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9474\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9474\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9474\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9474\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9474\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9474\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9474\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9474\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9474\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9474\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9474\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9474\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9474\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9474\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9474\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9474\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9474\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9474\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9474\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9474\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9474\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9474\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9474\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9474\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9474\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9474\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9474\n",
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9474\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9474\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9474\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9474\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9474\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9474\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9474\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9474\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9474\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9474\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9474\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9474\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9474\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9474\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9474\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9474\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9474\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9474\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9474\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9474\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9474\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9474\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9944e-04 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9474\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9415\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5456e-04 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9474\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2366e-04 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9474\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.9179e-04 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9474\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7100e-04 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9474\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.6243e-04 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9474\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.2088e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9474\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0979e-04 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9474\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.0240e-04 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9474\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.8370e-04 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9415\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6786e-04 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9474\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.4321e-04 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9474\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1811e-04 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9474\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0048e-04 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9474\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.8143e-04 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9474\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6604e-04 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9474\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6046e-04 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9474\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.4077e-04 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9474\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.2854e-04 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9474\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.1034e-04 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9474\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.9597e-04 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9474\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.8180e-04 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9474\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.7242e-04 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9474\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.6153e-04 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9474\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.5197e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9474\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.3928e-04 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9474\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.2593e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9474\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.1694e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9474\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0415e-04 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9474\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.9547e-04 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9474\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.8635e-04 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9474\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7513e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9474\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6921e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9474\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5885e-04 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9415\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5546e-04 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9415\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4204e-04 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9474\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3121e-04 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9474\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2339e-04 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9474\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.1921e-04 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9474\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.0774e-04 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9474\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0151e-04 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9474\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.9321e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9474\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 3.8806e-04 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9474\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.8075e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9474\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7398e-04 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9474\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6644e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9474\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5825e-04 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9474\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5377e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9474\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4667e-04 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9474\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4208e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9474\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3487e-04 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9474\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2904e-04 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9474\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2321e-04 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9474\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1757e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9474\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1425e-04 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9474\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0810e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9474\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0331e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9474\n",
      "Epoch 163/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9669e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9415\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9391e-04 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9415\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8794e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9415\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8236e-04 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9415\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7774e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9474\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7340e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9474\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7038e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9474\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6504e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9474\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6644e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9415\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5919e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9415\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5421e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9415\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4881e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9415\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4407e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9474\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4061e-04 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9474\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3733e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9474\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3330e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9474\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2986e-04 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9474\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2679e-04 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9474\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2254e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9474\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2019e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9474\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1695e-04 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9474\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1225e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9474\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1038e-04 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9474\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0728e-04 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9474\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0463e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9474\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0054e-04 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9474\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9821e-04 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9474\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.9509e-04 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9474\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9252e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9474\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9022e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9474\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8693e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9474\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8503e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9474\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8195e-04 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9474\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7942e-04 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9474\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7688e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9474\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7495e-04 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9415\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7201e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9415\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7049e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9474\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6794e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9474\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6541e-04 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9474\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6337e-04 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9474\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6087e-04 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9474\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5893e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9415\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5701e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9415\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5509e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9474\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5258e-04 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9415\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5032e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9474\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4836e-04 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9415\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4646e-04 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9474\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4542e-04 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9415\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4369e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9415\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4074e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9415\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3907e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9415\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3662e-04 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9415\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3487e-04 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9415\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3331e-04 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9415\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3152e-04 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9415\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3051e-04 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9415\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2897e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9415\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2718e-04 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9415\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2499e-04 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9415\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2383e-04 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9415\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2241e-04 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9415\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.2065e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9415\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1893e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9415\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1744e-04 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9415\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1602e-04 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9415\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1469e-04 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9415\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1347e-04 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9415\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1248e-04 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9415\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1063e-04 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9415\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0928e-04 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9415\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0767e-04 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9415\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0656e-04 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9415\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0543e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9415\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0403e-04 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9415\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0314e-04 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9415\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0155e-04 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9415\n",
      "Epoch 241/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0071e-04 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9415\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.9396e-05 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9415\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.8334e-05 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9415\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.6845e-05 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9415\n",
      "Epoch 245/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6075e-05 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9415\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.4744e-05 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9415\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3829e-05 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9415\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2877e-05 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9415\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.1761e-05 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9415\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0477e-05 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9415\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.9583e-05 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9415\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.8651e-05 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9415\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7421e-05 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9415\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.6609e-05 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9415\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.5519e-05 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9415\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.4277e-05 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9415\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.3319e-05 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9415\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.3084e-05 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9415\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.1545e-05 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9415\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0918e-05 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9415\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.9798e-05 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9415\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.8594e-05 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9415\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7781e-05 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9415\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6748e-05 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9415\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5903e-05 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9415\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.4816e-05 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9415\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3977e-05 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9415\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3111e-05 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9415\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.2228e-05 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9415\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1827e-05 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9415\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0727e-05 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9415\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.0350e-05 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9415\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.9204e-05 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9415\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8522e-05 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9415\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7853e-05 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9415\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7213e-05 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9415\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7060e-05 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9415\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5946e-05 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9415\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.4731e-05 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9415\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4027e-05 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9415\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3318e-05 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9415\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2549e-05 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9415\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.1897e-05 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9415\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.1264e-05 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9415\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.0611e-05 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9415\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.9952e-05 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9415\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.9490e-05 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9415\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.8932e-05 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9415\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.8072e-05 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9415\n",
      "Epoch 290/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.7700e-05 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9415\n",
      "Epoch 291/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.7026e-05 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9415\n",
      "Epoch 292/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.6199e-05 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9415\n",
      "Epoch 293/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.5709e-05 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9415\n",
      "Epoch 294/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5178e-05 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9415\n",
      "Epoch 295/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.4777e-05 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9415\n",
      "Epoch 296/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.4249e-05 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9415\n",
      "Epoch 297/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.3408e-05 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9415\n",
      "Epoch 298/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.2609e-05 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9415\n",
      "Epoch 299/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.2354e-05 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9415\n",
      "Epoch 300/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.1569e-05 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9415\n",
      "Epoch 301/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.1114e-05 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9415\n",
      "Epoch 302/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0482e-05 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9415\n",
      "Epoch 303/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.0026e-05 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9415\n",
      "Epoch 304/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.9575e-05 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9415\n",
      "Epoch 305/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.9032e-05 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9415\n",
      "Epoch 306/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.8470e-05 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9415\n",
      "Epoch 307/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.8041e-05 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9415\n",
      "Epoch 308/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.7366e-05 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9415\n",
      "Epoch 309/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.7362e-05 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9415\n",
      "Epoch 310/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6645e-05 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9415\n",
      "Epoch 311/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.6113e-05 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9415\n",
      "Epoch 312/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5462e-05 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9415\n",
      "Epoch 313/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 4.5218e-05 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9415\n",
      "Epoch 314/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4594e-05 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9415\n",
      "Epoch 315/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4233e-05 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9357\n",
      "Epoch 316/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3747e-05 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9357\n",
      "Epoch 317/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3459e-05 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9415\n",
      "Epoch 318/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.2879e-05 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9357\n",
      "Epoch 319/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.2331e-05 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9357\n",
      "Epoch 320/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.1943e-05 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9357\n",
      "Epoch 321/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.1443e-05 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9357\n",
      "Epoch 322/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1064e-05 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9357\n",
      "Epoch 323/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.0617e-05 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9415\n",
      "Epoch 324/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.0296e-05 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9474\n",
      "Epoch 325/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.0005e-05 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9357\n",
      "Epoch 326/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9581e-05 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9357\n",
      "Epoch 327/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.9062e-05 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9415\n",
      "Epoch 328/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.8678e-05 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9415\n",
      "Epoch 329/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.8164e-05 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9415\n",
      "Epoch 330/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.7824e-05 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9415\n",
      "Epoch 331/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7441e-05 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9415\n",
      "Epoch 332/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7086e-05 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9415\n",
      "Epoch 333/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.6800e-05 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9415\n",
      "Epoch 334/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6362e-05 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9415\n",
      "Epoch 335/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.6029e-05 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9415\n",
      "Epoch 336/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.5716e-05 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9415\n",
      "Epoch 337/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5481e-05 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9415\n",
      "Epoch 338/600\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.4980e-05 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9474\n",
      "Epoch 339/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4706e-05 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9474\n",
      "Epoch 340/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4256e-05 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9415\n",
      "Epoch 341/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4043e-05 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9415\n",
      "Epoch 342/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.3621e-05 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9415\n",
      "Epoch 343/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3381e-05 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9474\n",
      "Epoch 344/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3055e-05 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9415\n",
      "Epoch 345/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2649e-05 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9474\n",
      "Epoch 346/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2406e-05 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9474\n",
      "Epoch 347/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2053e-05 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9474\n",
      "Epoch 348/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1770e-05 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9474\n",
      "Epoch 349/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1406e-05 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9415\n",
      "Epoch 350/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1211e-05 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9415\n",
      "Epoch 351/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0829e-05 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9415\n",
      "Epoch 352/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0745e-05 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9415\n",
      "Epoch 353/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0279e-05 - accuracy: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.9415\n",
      "Epoch 354/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9963e-05 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9415\n",
      "Epoch 355/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9866e-05 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9415\n",
      "Epoch 356/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9518e-05 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9415\n",
      "Epoch 357/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9224e-05 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9415\n",
      "Epoch 358/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8836e-05 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9415\n",
      "Epoch 359/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8413e-05 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9415\n",
      "Epoch 360/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8231e-05 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9415\n",
      "Epoch 361/600\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 2.7863e-05 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9415\n",
      "Epoch 362/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.7725e-05 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9415\n",
      "Epoch 363/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7400e-05 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9415\n",
      "Epoch 364/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7133e-05 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9415\n",
      "Epoch 365/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6864e-05 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9415\n",
      "Epoch 366/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6578e-05 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9415\n",
      "Epoch 367/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6346e-05 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9415\n",
      "Epoch 368/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6198e-05 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9415\n",
      "Epoch 369/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5868e-05 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9415\n",
      "Epoch 370/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5636e-05 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9415\n",
      "Epoch 371/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.5419e-05 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9415\n",
      "Epoch 372/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5258e-05 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9415\n",
      "Epoch 373/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4857e-05 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9415\n",
      "Epoch 374/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4715e-05 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9415\n",
      "Epoch 375/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4441e-05 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9415\n",
      "Epoch 376/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4299e-05 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9415\n",
      "Epoch 377/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4064e-05 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9415\n",
      "Epoch 378/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3787e-05 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9415\n",
      "Epoch 379/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3712e-05 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9415\n",
      "Epoch 380/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3365e-05 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9415\n",
      "Epoch 381/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3197e-05 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9415\n",
      "Epoch 382/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2935e-05 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9415\n",
      "Epoch 383/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 2.2628e-05 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9415\n",
      "Epoch 384/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2532e-05 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9415\n",
      "Epoch 385/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2201e-05 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9415\n",
      "Epoch 386/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1926e-05 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9415\n",
      "Epoch 387/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1802e-05 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9415\n",
      "Epoch 388/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1575e-05 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9415\n",
      "Epoch 389/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1355e-05 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9415\n",
      "Epoch 390/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1145e-05 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9415\n",
      "Epoch 391/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0986e-05 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9415\n",
      "Epoch 392/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0763e-05 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9415\n",
      "Epoch 393/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0605e-05 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9415\n",
      "Epoch 394/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0485e-05 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9415\n",
      "Epoch 395/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0310e-05 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9415\n",
      "Epoch 396/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0065e-05 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9415\n",
      "Epoch 397/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9878e-05 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9415\n",
      "Epoch 398/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9691e-05 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9415\n",
      "Epoch 399/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9462e-05 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9415\n",
      "Epoch 400/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9345e-05 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9415\n",
      "Epoch 401/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9089e-05 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9415\n",
      "Epoch 402/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8961e-05 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9415\n",
      "Epoch 403/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8765e-05 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9415\n",
      "Epoch 404/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.8629e-05 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9415\n",
      "Epoch 405/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8444e-05 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9415\n",
      "Epoch 406/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8268e-05 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9415\n",
      "Epoch 407/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8116e-05 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9415\n",
      "Epoch 408/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7976e-05 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9415\n",
      "Epoch 409/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7807e-05 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9415\n",
      "Epoch 410/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7581e-05 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9415\n",
      "Epoch 411/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7429e-05 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9415\n",
      "Epoch 412/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7347e-05 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9415\n",
      "Epoch 413/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7263e-05 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9415\n",
      "Epoch 414/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7079e-05 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9415\n",
      "Epoch 415/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6843e-05 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9415\n",
      "Epoch 416/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6633e-05 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9415\n",
      "Epoch 417/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6495e-05 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9415\n",
      "Epoch 418/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6348e-05 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9415\n",
      "Epoch 419/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6235e-05 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9415\n",
      "Epoch 420/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6086e-05 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9415\n",
      "Epoch 421/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5942e-05 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9415\n",
      "Epoch 422/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5802e-05 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9415\n",
      "Epoch 423/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5674e-05 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9415\n",
      "Epoch 424/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5480e-05 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9415\n",
      "Epoch 425/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.5343e-05 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9415\n",
      "Epoch 426/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5225e-05 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9415\n",
      "Epoch 427/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5030e-05 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9415\n",
      "Epoch 428/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.4997e-05 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9415\n",
      "Epoch 429/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4793e-05 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9415\n",
      "Epoch 430/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4636e-05 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9415\n",
      "Epoch 431/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4533e-05 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9415\n",
      "Epoch 432/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4403e-05 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9415\n",
      "Epoch 433/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4288e-05 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9415\n",
      "Epoch 434/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4136e-05 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9415\n",
      "Epoch 435/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4041e-05 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9415\n",
      "Epoch 436/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3874e-05 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9415\n",
      "Epoch 437/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3786e-05 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9415\n",
      "Epoch 438/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3673e-05 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9415\n",
      "Epoch 439/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3535e-05 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9415\n",
      "Epoch 440/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3480e-05 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9415\n",
      "Epoch 441/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.3356e-05 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9415\n",
      "Epoch 442/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3223e-05 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9415\n",
      "Epoch 443/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3072e-05 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.9415\n",
      "Epoch 444/600\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.2984e-05 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9415\n",
      "Epoch 445/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.2835e-05 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9415\n",
      "Epoch 446/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.2743e-05 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9415\n",
      "Epoch 447/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2658e-05 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9415\n",
      "Epoch 448/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2532e-05 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9415\n",
      "Epoch 449/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2400e-05 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9415\n",
      "Epoch 450/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2335e-05 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9415\n",
      "Epoch 451/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2215e-05 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9415\n",
      "Epoch 452/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2110e-05 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9415\n",
      "Epoch 453/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1978e-05 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9415\n",
      "Epoch 454/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1881e-05 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9415\n",
      "Epoch 455/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1778e-05 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9415\n",
      "Epoch 456/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1690e-05 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9415\n",
      "Epoch 457/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1593e-05 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9415\n",
      "Epoch 458/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1488e-05 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9415\n",
      "Epoch 459/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1406e-05 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9415\n",
      "Epoch 460/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1306e-05 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9415\n",
      "Epoch 461/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1200e-05 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9415\n",
      "Epoch 462/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1111e-05 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9415\n",
      "Epoch 463/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.1009e-05 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9415\n",
      "Epoch 464/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0923e-05 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9415\n",
      "Epoch 465/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0824e-05 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9415\n",
      "Epoch 466/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0745e-05 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9415\n",
      "Epoch 467/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0649e-05 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.9415\n",
      "Epoch 468/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0559e-05 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9415\n",
      "Epoch 469/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0473e-05 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9415\n",
      "Epoch 470/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0385e-05 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.9415\n",
      "Epoch 471/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0305e-05 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9415\n",
      "Epoch 472/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0188e-05 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9415\n",
      "Epoch 473/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0109e-05 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9415\n",
      "Epoch 474/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0055e-05 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9415\n",
      "Epoch 475/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9355e-06 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9415\n",
      "Epoch 476/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.8558e-06 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9415\n",
      "Epoch 477/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.7904e-06 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9415\n",
      "Epoch 478/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.6796e-06 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.9415\n",
      "Epoch 479/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5785e-06 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9415\n",
      "Epoch 480/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.4895e-06 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9415\n",
      "Epoch 481/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.4241e-06 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9415\n",
      "Epoch 482/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.3424e-06 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9415\n",
      "Epoch 483/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.2586e-06 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9415\n",
      "Epoch 484/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.1854e-06 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9415\n",
      "Epoch 485/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.0918e-06 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9415\n",
      "Epoch 486/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.0415e-06 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9415\n",
      "Epoch 487/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.9772e-06 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9415\n",
      "Epoch 488/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.8682e-06 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9415\n",
      "Epoch 489/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.7832e-06 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.9415\n",
      "Epoch 490/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.7343e-06 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9415\n",
      "Epoch 491/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.6504e-06 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9415\n",
      "Epoch 492/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.5608e-06 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9415\n",
      "Epoch 493/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.5048e-06 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9415\n",
      "Epoch 494/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.4437e-06 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9415\n",
      "Epoch 495/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.3654e-06 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9415\n",
      "Epoch 496/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.3012e-06 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9415\n",
      "Epoch 497/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.2376e-06 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9415\n",
      "Epoch 498/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.1595e-06 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9415\n",
      "Epoch 499/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 8.1221e-06 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9415\n",
      "Epoch 500/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0570e-06 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9415\n",
      "Epoch 501/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.9629e-06 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9415\n",
      "Epoch 502/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.8993e-06 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9415\n",
      "Epoch 503/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.8555e-06 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9415\n",
      "Epoch 504/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7809e-06 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9415\n",
      "Epoch 505/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7053e-06 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9415\n",
      "Epoch 506/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.6549e-06 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9415\n",
      "Epoch 507/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5800e-06 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9415\n",
      "Epoch 508/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5116e-06 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9415\n",
      "Epoch 509/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4673e-06 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9415\n",
      "Epoch 510/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.4038e-06 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9415\n",
      "Epoch 511/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3511e-06 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9415\n",
      "Epoch 512/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.2703e-06 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9415\n",
      "Epoch 513/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.2213e-06 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9415\n",
      "Epoch 514/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1707e-06 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9415\n",
      "Epoch 515/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.0787e-06 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9415\n",
      "Epoch 516/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.0405e-06 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9415\n",
      "Epoch 517/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.9794e-06 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9415\n",
      "Epoch 518/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.9107e-06 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9415\n",
      "Epoch 519/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8709e-06 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9415\n",
      "Epoch 520/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7963e-06 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9415\n",
      "Epoch 521/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.7503e-06 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9415\n",
      "Epoch 522/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.6959e-06 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.9415\n",
      "Epoch 523/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6443e-06 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9415\n",
      "Epoch 524/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5980e-06 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9415\n",
      "Epoch 525/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5365e-06 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9415\n",
      "Epoch 526/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4729e-06 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9415\n",
      "Epoch 527/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.4356e-06 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9415\n",
      "Epoch 528/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3749e-06 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9415\n",
      "Epoch 529/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3294e-06 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9415\n",
      "Epoch 530/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2776e-06 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9415\n",
      "Epoch 531/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2239e-06 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9415\n",
      "Epoch 532/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.1761e-06 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9415\n",
      "Epoch 533/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.1374e-06 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9415\n",
      "Epoch 534/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.0888e-06 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9415\n",
      "Epoch 535/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.0263e-06 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9415\n",
      "Epoch 536/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.9682e-06 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9415\n",
      "Epoch 537/600\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 5.9163e-06 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9415\n",
      "Epoch 538/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.8685e-06 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9415\n",
      "Epoch 539/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.8239e-06 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9415\n",
      "Epoch 540/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.7993e-06 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9474\n",
      "Epoch 541/600\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 5.7309e-06 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9415\n",
      "Epoch 542/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.6782e-06 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9415\n",
      "Epoch 543/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.6383e-06 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9415\n",
      "Epoch 544/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.5770e-06 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9415\n",
      "Epoch 545/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5616e-06 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9415\n",
      "Epoch 546/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5246e-06 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9415\n",
      "Epoch 547/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.4869e-06 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9415\n",
      "Epoch 548/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.4261e-06 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9415\n",
      "Epoch 549/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.3722e-06 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9415\n",
      "Epoch 550/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.3223e-06 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9415\n",
      "Epoch 551/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.2812e-06 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9415\n",
      "Epoch 552/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.2345e-06 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9415\n",
      "Epoch 553/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.2055e-06 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9415\n",
      "Epoch 554/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1617e-06 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9415\n",
      "Epoch 555/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1040e-06 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9415\n",
      "Epoch 556/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.0702e-06 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9415\n",
      "Epoch 557/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.0433e-06 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9415\n",
      "Epoch 558/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9782e-06 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9415\n",
      "Epoch 559/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 4.9590e-06 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9415\n",
      "Epoch 560/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9208e-06 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9415\n",
      "Epoch 561/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.8789e-06 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9415\n",
      "Epoch 562/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.8295e-06 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9415\n",
      "Epoch 563/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.8017e-06 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9415\n",
      "Epoch 564/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.7565e-06 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9415\n",
      "Epoch 565/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.7104e-06 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9415\n",
      "Epoch 566/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6855e-06 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9474\n",
      "Epoch 567/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6406e-06 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9474\n",
      "Epoch 568/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6046e-06 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9415\n",
      "Epoch 569/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5661e-06 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9474\n",
      "Epoch 570/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.5353e-06 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9415\n",
      "Epoch 571/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4954e-06 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9415\n",
      "Epoch 572/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4714e-06 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9415\n",
      "Epoch 573/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4353e-06 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9415\n",
      "Epoch 574/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4026e-06 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9474\n",
      "Epoch 575/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3632e-06 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9415\n",
      "Epoch 576/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3314e-06 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.9474\n",
      "Epoch 577/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.2921e-06 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9415\n",
      "Epoch 578/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.2647e-06 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9415\n",
      "Epoch 579/600\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 4.2221e-06 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9415\n",
      "Epoch 580/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 4.1790e-06 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9415\n",
      "Epoch 581/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1616e-06 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9415\n",
      "Epoch 582/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1297e-06 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9415\n",
      "Epoch 583/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.0918e-06 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9415\n",
      "Epoch 584/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.0609e-06 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9415\n",
      "Epoch 585/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.0158e-06 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9415\n",
      "Epoch 586/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9858e-06 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9415\n",
      "Epoch 587/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.9517e-06 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9415\n",
      "Epoch 588/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9138e-06 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9415\n",
      "Epoch 589/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.8837e-06 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9415\n",
      "Epoch 590/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.8671e-06 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9415\n",
      "Epoch 591/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.8286e-06 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9415\n",
      "Epoch 592/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.7983e-06 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9415\n",
      "Epoch 593/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7645e-06 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9415\n",
      "Epoch 594/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.7352e-06 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9415\n",
      "Epoch 595/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7099e-06 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9415\n",
      "Epoch 596/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.6838e-06 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9415\n",
      "Epoch 597/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.6441e-06 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9415\n",
      "Epoch 598/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.6259e-06 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9415\n",
      "Epoch 599/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5996e-06 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9415\n",
      "Epoch 600/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5724e-06 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc5d5abcd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "\n",
    "# Binary Classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test), verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.9415\n",
      "EVALUATE MODEL BY EPOCH=600\n",
      "Test Loss: 0.431334\n",
      "Test Accuracy: 0.941520\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"EVALUATE MODEL BY EPOCH=600\")\n",
    "print(f\"Test Loss: {test_loss:.6f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
